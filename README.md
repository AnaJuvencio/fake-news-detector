# ğŸ•µï¸ Detector de Fake News com AnÃ¡lise de Fairness

Este projeto implementa um sistema completo de detecÃ§Ã£o de fake news com foco especial em anÃ¡lise de fairness, utilizando os datasets FakeBR e FakeRecogna. O sistema inclui uma API REST, armazenamento em S3 (LocalStack), tracking de experimentos com MLflow e pipelines de CI/CD.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [InstalaÃ§Ã£o e Setup](#instalaÃ§Ã£o-e-setup)
- [Como Usar](#como-usar)
- [AnÃ¡lise de Fairness](#anÃ¡lise-de-fairness)
- [API](#api)
- [Docker e LocalStack](#docker-e-localstack)
- [CI/CD](#cicd)
- [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um detector de fake news com as seguintes caracterÃ­sticas:

- **Datasets**: FakeBR e FakeRecogna
- **MÃ©tricas de Fairness**: Demographic Parity Index (DI) e Statistical Parity Difference (SPD)
- **API REST**: FastAPI para servir prediÃ§Ãµes
- **Armazenamento**: S3 simulado via LocalStack
- **Tracking**: MLflow para experimentos
- **CI/CD**: GitHub Actions com testes automatizados
- **ContainerizaÃ§Ã£o**: Docker para deploy

## ğŸ“ Estrutura do Projeto

```
fake-news-detector/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Datasets originais (nÃ£o versionados)
â”‚   â”œâ”€â”€ processed/          # Datasets limpos/padronizados
â”‚   â””â”€â”€ reports/            # GrÃ¡ficos DI/SPD e tabelas do relatÃ³rio
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_preprocess_fakebr.ipynb       # PrÃ©-processamento FakeBR
â”‚   â”œâ”€â”€ 02_preprocess_fakerecogna.ipynb  # PrÃ©-processamento FakeRecogna
â”‚   â”œâ”€â”€ 03_fairness_analysis.ipynb       # AnÃ¡lise DI/SPD
â”‚   â””â”€â”€ 04_model_training.ipynb          # Treino e export de modelos
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ train.py                     # Scripts de treinamento
â”‚   â”‚   â””â”€â”€ evaluate.py                  # MÃ©tricas e avaliaÃ§Ã£o
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ s3_client.py                 # IntegraÃ§Ã£o com LocalStack S3
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ app.py                       # FastAPI application
â”‚       â””â”€â”€ model_loader.py              # Carregamento de modelos do S3
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.api                   # Container da API
â”‚   â”œâ”€â”€ docker-compose.yml               # OrquestraÃ§Ã£o completa
â”‚   â””â”€â”€ localstack_bootstrap.sh          # Setup automÃ¡tico do S3
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                       # Pipeline CI/CD
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ InstalaÃ§Ã£o e Setup

### PrÃ©-requisitos

- Python 3.8+
- Docker e Docker Compose
- Git

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/fake-news-detector.git
cd fake-news-detector
```

### 2. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 3. Configure o ambiente com Docker

```bash
# Inicia todos os serviÃ§os (LocalStack, MLflow, API, Jupyter)
cd docker
docker-compose up -d

# Verifica se os serviÃ§os estÃ£o rodando
docker-compose ps
```

### 4. Acesse os serviÃ§os

- **API**: http://localhost:8000
- **MLflow**: http://localhost:5000
- **Jupyter**: http://localhost:8888 (token: `fake-news-dev`)
- **LocalStack S3**: http://localhost:4566

## ğŸ’» Como Usar

### 1. Processamento dos Datasets

Execute os notebooks na ordem:

1. `01_preprocess_fakebr.ipynb` - Processa o dataset FakeBR
2. `02_preprocess_fakerecogna.ipynb` - Processa o FakeRecogna
3. `04_model_training.ipynb` - Treina os modelos

### 2. AnÃ¡lise de Fairness

Execute o notebook `03_fairness_analysis.ipynb` para:

- Calcular mÃ©tricas DI (Demographic Parity Index)
- Calcular mÃ©tricas SPD (Statistical Parity Difference)
- Gerar visualizaÃ§Ãµes para o relatÃ³rio
- Salvar resultados em `data/reports/`

### 3. Usando a API

```python
import requests

# Teste de saÃºde
response = requests.get("http://localhost:8000/health")
print(response.json())

# PrediÃ§Ã£o individual
text = "Esta Ã© uma notÃ­cia sobre polÃ­tica"
response = requests.post(
    "http://localhost:8000/predict",
    json={"text": text}
)
print(response.json())
```

### 4. Usando via linha de comando

```bash
# Treino de modelo
python src/model/train.py

# AvaliaÃ§Ã£o
python src/model/evaluate.py

# Teste da API
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"text": "Exemplo de notÃ­cia para anÃ¡lise"}'
```

## ğŸ“Š AnÃ¡lise de Fairness

O projeto implementa duas mÃ©tricas principais de fairness:

### Demographic Parity Index (DI)
- **FÃ³rmula**: DI = min(P(Å¶=1|A=a)) / max(P(Å¶=1|A=a))
- **InterpretaÃ§Ã£o**: Valores prÃ³ximos a 1.0 indicam maior fairness
- **Uso**: Mede se diferentes grupos recebem prediÃ§Ãµes positivas em taxas similares

### Statistical Parity Difference (SPD)
- **FÃ³rmula**: SPD = |P(Å¶=1|A=privileged) - P(Å¶=1|A=unprivileged)|
- **InterpretaÃ§Ã£o**: Valores prÃ³ximos a 0.0 indicam maior fairness
- **Uso**: Mede a diferenÃ§a absoluta nas taxas de prediÃ§Ãµes positivas

### VisualizaÃ§Ãµes Geradas

- GrÃ¡ficos de barras comparando DI/SPD entre modelos
- DistribuiÃ§Ãµes de prediÃ§Ãµes por grupo sensÃ­vel
- Matrizes de confusÃ£o segmentadas
- RelatÃ³rios de fairness exportados para `data/reports/`

## ğŸŒ API

### Endpoints Principais

| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/` | GET | Health check bÃ¡sico |
| `/health` | GET | Status detalhado da API |
| `/predict` | POST | PrediÃ§Ã£o individual |
| `/batch_predict` | POST | PrediÃ§Ã£o em lote |
| `/model/info` | GET | InformaÃ§Ãµes do modelo |
| `/model/reload` | POST | Recarrega modelo do S3 |

### Exemplo de Uso

```python
# PrediÃ§Ã£o individual
{
  "text": "NotÃ­cia para anÃ¡lise"
}

# Resposta
{
  "prediction": "real",
  "confidence": 0.87,
  "probabilities": {
    "real": 0.87,
    "fake": 0.13
  }
}
```

## ğŸ³ Docker e LocalStack

### ServiÃ§os IncluÃ­dos

- **fake-news-api**: API FastAPI
- **localstack**: SimulaÃ§Ã£o do AWS S3
- **mlflow**: Tracking de experimentos
- **jupyter**: Ambiente de desenvolvimento

### Comandos Ãšteis

```bash
# Inicia todos os serviÃ§os
docker-compose up -d

# Logs da API
docker-compose logs fake-news-api

# Acessa container da API
docker-compose exec fake-news-api bash

# Para todos os serviÃ§os
docker-compose down

# Rebuild da API
docker-compose build fake-news-api
```

### LocalStack S3

O LocalStack simula o AWS S3 localmente:

```bash
# Configurar AWS CLI para LocalStack
aws configure set aws_access_key_id test
aws configure set aws_secret_access_key test
aws configure set default.region us-east-1

# Listar modelos
aws --endpoint-url=http://localhost:4566 s3 ls s3://fake-news-models/models/

# Upload manual de modelo
aws --endpoint-url=http://localhost:4566 s3 cp model.joblib s3://fake-news-models/models/
```

## ğŸ”„ CI/CD

O pipeline GitHub Actions inclui:

### Testes
- **Unit tests**: pytest com coverage
- **Lint**: flake8, black, isort
- **Security**: bandit, safety
- **Notebooks**: nbval para validaÃ§Ã£o

### Build e Deploy
- **Docker build**: ConstrÃ³i imagem da API
- **Integration tests**: Testa com LocalStack
- **Security scanning**: AnÃ¡lise de vulnerabilidades

### ConfiguraÃ§Ã£o

O pipeline Ã© ativado automaticamente em:
- Push para `main` ou `develop`
- Pull requests para `main`

## ğŸ¤ ContribuiÃ§Ã£o

### Setup de Desenvolvimento

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature
3. Instale dependÃªncias de desenvolvimento:

```bash
pip install -r requirements.txt
pip install pre-commit
pre-commit install
```

4. Execute testes localmente:

```bash
pytest tests/ -v
flake8 src/
black --check src/
isort --check-only src/
```

### Guidelines

- Siga PEP 8 para cÃ³digo Python
- Adicione testes para novas funcionalidades
- Documente funÃ§Ãµes e classes
- Use type hints
- Atualize README se necessÃ¡rio

## ğŸ“ˆ MÃ©tricas e Monitoramento

### MLflow

- **Tracking URI**: http://localhost:5000
- **Experiments**: ComparaÃ§Ã£o de modelos
- **Artifacts**: Modelos e grÃ¡ficos
- **Metrics**: Accuracy, Precision, Recall, F1, DI, SPD

### Logs

- **API Logs**: DisponÃ­veis via `docker-compose logs`
- **Model Performance**: Registrado no MLflow
- **Fairness Metrics**: Salvos em `data/reports/`

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# API
PORT=8000
HOST=0.0.0.0

# S3 (LocalStack)
S3_ENDPOINT=http://localhost:4566
S3_BUCKET=fake-news-models
MODEL_KEY=models/best_model.joblib
VECTORIZER_KEY=models/vectorizer.joblib

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000
```

### ConfiguraÃ§Ã£o Local

Crie um arquivo `.env` na raiz do projeto:

```env
S3_ENDPOINT=http://localhost:4566
S3_BUCKET=fake-news-models
MLFLOW_TRACKING_URI=http://localhost:5000
```

## ğŸ“š ReferÃªncias

- [FakeBR Dataset](https://github.com/roneysco/Fake.br-Corpus)
- [FakeRecogna Dataset](https://www.kaggle.com/datasets/ruchi798/fakerecogna)
- [Fairlearn Documentation](https://fairlearn.org/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [LocalStack Documentation](https://docs.localstack.cloud/)
- [MLflow Documentation](https://mlflow.org/docs/)

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ“ Contato

- **Autor**: [Seu Nome]
- **Email**: [seu-email@exemplo.com]
- **GitHub**: [seu-usuario]

---

**Nota**: Este Ã© um projeto acadÃªmico com foco em anÃ¡lise de fairness em modelos de ML. Os dados dos datasets nÃ£o estÃ£o incluÃ­dos no repositÃ³rio devido ao tamanho e licenÃ§as especÃ­ficas.