{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b428e32",
   "metadata": {},
   "source": [
    "# Pr√©-processamento do Dataset FakeBR\n",
    "\n",
    "Este notebook realiza o pr√©-processamento do dataset FakeBR, incluindo limpeza de dados, normaliza√ß√£o de texto e prepara√ß√£o para an√°lise de fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20d13387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vers√µes dos pacotes:\n",
      "   - pandas: 2.3.3\n",
      "   - numpy: 2.3.4\n",
      "   - nltk: 3.9.2\n",
      "   - sklearn: 1.7.2\n",
      "   - matplotlib: 3.10.7\n",
      "   - seaborn: 0.13.2\n",
      "\n",
      "Verificando recursos do NLTK...\n",
      "Tokenizer punkt j√° dispon√≠vel\n",
      "Stopwords j√° dispon√≠veis\n",
      "Todas as importa√ß√µes conclu√≠das com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importa√ß√µes necess√°rias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "\n",
    "# Verifica√ß√£o das vers√µes dos pacotes principais\n",
    "print(\"Vers√µes dos pacotes:\")\n",
    "print(f\"   - pandas: {pd.__version__}\")\n",
    "print(f\"   - numpy: {np.__version__}\")\n",
    "print(f\"   - nltk: {nltk.__version__}\")\n",
    "print(f\"   - sklearn: {sklearn.__version__}\")\n",
    "print(f\"   - matplotlib: {matplotlib.__version__}\")\n",
    "print(f\"   - seaborn: {sns.__version__}\")\n",
    "\n",
    "# Download recursos do NLTK se necess√°rio\n",
    "print(\"\\nVerificando recursos do NLTK...\")\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    print(\"Tokenizer punkt j√° dispon√≠vel\")\n",
    "except LookupError:\n",
    "    print(\"Baixando tokenizer punkt...\")\n",
    "    nltk.download('punkt')\n",
    "    \n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    print(\"Stopwords j√° dispon√≠veis\")\n",
    "except LookupError:\n",
    "    print(\"Baixando stopwords...\")\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "print(\"Todas as importa√ß√µes conclu√≠das com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce8edc",
   "metadata": {},
   "source": [
    "## 1. Carregamento de Dataset e An√°lise Explorat√≥ria: \n",
    "Primeiro vamos carregar o dataset e depois realizar uma an√°lise explorat√≥ria dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f12db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset encontrado!\n",
      "Shape do dataset: 7200 linhas x 27 colunas\n",
      "Colunas dispon√≠veis: ['conteudo', 'autor', 'link', 'categoria', 'data_publicacao', 'n_tokens', 'n_palavras_sem_pontuacao', 'n_tipos', 'n_links_na_noticia', 'n_palavras_maiusculas', 'n_verbos', 'n_verbos_subjuntivo_imperativo', 'n_substantivos', 'n_adjetivos', 'n_adverbios', 'n_verbos_modais', 'n_pronomes_pessoas_singulares_primeiro_segundo', 'n_pronomes_plurais_primeiro', 'n_pronomes', 'pausas', 'n_caracteres', 'compr_medio_frase', 'compr_medio_palavra', 'porcent_noticias_erros_ortograficos', 'emotividade', 'diversidade', 'classificacao']\n",
      "\n",
      "==================================================\n",
      "Primeiras 3 linhas:\n",
      "Shape do dataset: 7200 linhas x 27 colunas\n",
      "Colunas dispon√≠veis: ['conteudo', 'autor', 'link', 'categoria', 'data_publicacao', 'n_tokens', 'n_palavras_sem_pontuacao', 'n_tipos', 'n_links_na_noticia', 'n_palavras_maiusculas', 'n_verbos', 'n_verbos_subjuntivo_imperativo', 'n_substantivos', 'n_adjetivos', 'n_adverbios', 'n_verbos_modais', 'n_pronomes_pessoas_singulares_primeiro_segundo', 'n_pronomes_plurais_primeiro', 'n_pronomes', 'pausas', 'n_caracteres', 'compr_medio_frase', 'compr_medio_palavra', 'porcent_noticias_erros_ortograficos', 'emotividade', 'diversidade', 'classificacao']\n",
      "\n",
      "==================================================\n",
      "Primeiras 3 linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conteudo</th>\n",
       "      <th>autor</th>\n",
       "      <th>link</th>\n",
       "      <th>categoria</th>\n",
       "      <th>data_publicacao</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_palavras_sem_pontuacao</th>\n",
       "      <th>n_tipos</th>\n",
       "      <th>n_links_na_noticia</th>\n",
       "      <th>n_palavras_maiusculas</th>\n",
       "      <th>...</th>\n",
       "      <th>n_pronomes_plurais_primeiro</th>\n",
       "      <th>n_pronomes</th>\n",
       "      <th>pausas</th>\n",
       "      <th>n_caracteres</th>\n",
       "      <th>compr_medio_frase</th>\n",
       "      <th>compr_medio_palavra</th>\n",
       "      <th>porcent_noticias_erros_ortograficos</th>\n",
       "      <th>emotividade</th>\n",
       "      <th>diversidade</th>\n",
       "      <th>classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K√°tia Abreu diz que vai colocar sua expuls√£o e...</td>\n",
       "      <td>mrk</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/30/katia...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>211</td>\n",
       "      <td>185</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>815</td>\n",
       "      <td>14.2308</td>\n",
       "      <td>4.40541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Ray peita Bolsonaro, chama-o de ¬ìconservad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/24/dr-ra...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>289</td>\n",
       "      <td>254</td>\n",
       "      <td>163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>1205</td>\n",
       "      <td>18.1429</td>\n",
       "      <td>4.74409</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.641732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reinaldo Azevedo desmascarado pela Pol√≠cia Fed...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://afolhabrasil.com.br/politica/reinaldo-...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>304</td>\n",
       "      <td>275</td>\n",
       "      <td>170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.8125</td>\n",
       "      <td>1344</td>\n",
       "      <td>17.1875</td>\n",
       "      <td>4.88727</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            conteudo autor  \\\n",
       "0  K√°tia Abreu diz que vai colocar sua expuls√£o e...   mrk   \n",
       "1  Dr. Ray peita Bolsonaro, chama-o de ¬ìconservad...   NaN   \n",
       "2  Reinaldo Azevedo desmascarado pela Pol√≠cia Fed...   NaN   \n",
       "\n",
       "                                                link categoria  \\\n",
       "0  https://ceticismopolitico.com/2017/11/30/katia...  politica   \n",
       "1  https://ceticismopolitico.com/2017/11/24/dr-ra...  politica   \n",
       "2  https://afolhabrasil.com.br/politica/reinaldo-...  politica   \n",
       "\n",
       "  data_publicacao  n_tokens  n_palavras_sem_pontuacao  n_tipos  \\\n",
       "0      2017-11-30       211                       185      120   \n",
       "1      2017-11-24       289                       254      163   \n",
       "2      2017-05-23       304                       275      170   \n",
       "\n",
       "   n_links_na_noticia  n_palavras_maiusculas  ...  \\\n",
       "0                 0.0                      6  ...   \n",
       "1                 0.0                      0  ...   \n",
       "2                 0.0                      0  ...   \n",
       "\n",
       "   n_pronomes_plurais_primeiro  n_pronomes  pausas  n_caracteres  \\\n",
       "0                            0          26  2.0000           815   \n",
       "1                            0          20  2.5000          1205   \n",
       "2                            0          18  1.8125          1344   \n",
       "\n",
       "   compr_medio_frase  compr_medio_palavra  \\\n",
       "0            14.2308              4.40541   \n",
       "1            18.1429              4.74409   \n",
       "2            17.1875              4.88727   \n",
       "\n",
       "   porcent_noticias_erros_ortograficos  emotividade  diversidade  \\\n",
       "0                             0.000000     0.263158     0.648649   \n",
       "1                             0.007874     0.241667     0.641732   \n",
       "2                             0.003636     0.127820     0.618182   \n",
       "\n",
       "   classificacao  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "xlsx_path = \"../data/raw/fakeBr.xlsx\"\n",
    "csv_path = \"../data/processed/fakeBr_dataset.csv\"\n",
    "\n",
    "# 1Verifica se existe o Excel e converte para CSV (s√≥ se ainda n√£o existir)\n",
    "if os.path.exists(xlsx_path) and not os.path.exists(csv_path):\n",
    "    print(\"Convertendo Excel (.xlsx) para CSV...\")\n",
    "    df_temp = pd.read_excel(xlsx_path)\n",
    "    df_temp.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "    print(\"Convers√£o conclu√≠da!\")\n",
    "\n",
    "# Carrega o CSV se existir\n",
    "if os.path.exists(csv_path):\n",
    "    print(\"Dataset encontrado!\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Informa√ß√µes b√°sicas\n",
    "    print(f\"Shape do dataset: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
    "    print(f\"Colunas dispon√≠veis: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Visualizar amostra\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Primeiras 3 linhas:\")\n",
    "    display(df.head(3))\n",
    "\n",
    "# Caso o dataset n√£o exista\n",
    "else:\n",
    "    print(\"Dataset n√£o encontrado!\")\n",
    "\n",
    "    # Cria dados de exemplo (para testes)\n",
    "    print(\"\\n Criando dados de exemplo para teste...\")\n",
    "    df = pd.DataFrame({\n",
    "        'text': [\n",
    "            'Esta √© uma not√≠cia verdadeira sobre pol√≠tica',\n",
    "            'FAKE: Not√≠cia falsa inventada para teste',\n",
    "            'Not√≠cia real sobre economia brasileira'\n",
    "        ],\n",
    "        'label': ['real', 'fake', 'real']\n",
    "    })\n",
    "    print(\"Dados de exemplo criados!\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed453554",
   "metadata": {},
   "source": [
    "Esse bloco √© o in√≠cio da EDA (Exploratory Data Analysis) do projeto de detec√ß√£o de fake news. Ele permite validar se o dataset Fake.Br foi carregado corretamente, se h√° dados faltantes, se as classes est√£o balanceadas e se os tipos de dados est√£o adequados antes da an√°lise de vieses.\n",
    "\n",
    "| Dataset         | Nome da coluna  | Significado no arquivo original         |\n",
    "| --------------- | --------------- | --------------------------------------- |\n",
    "| **Fake.Br**     | `classificacao` | `1 = fake news` e `0 = real` (inverso!) |\n",
    "\n",
    "No Fake.Br, o c√≥digo precisaria inverter o mapeamento, vamos deixar tudo padronizado com seguran√ßa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54e0c405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An√°lise explorat√≥ria dos dados iniciada...\n",
      "==================================================\n",
      "Dimens√µes: 7200 linhas x 27\n",
      "Mem√≥ria: 48.13 MB\n",
      "Valores ausentes por coluna:\n",
      "conteudo                                             0\n",
      "autor                                             3601\n",
      "link                                                 0\n",
      "categoria                                            0\n",
      "data_publicacao                                      0\n",
      "n_tokens                                             0\n",
      "n_palavras_sem_pontuacao                             0\n",
      "n_tipos                                              0\n",
      "n_links_na_noticia                                1393\n",
      "n_palavras_maiusculas                                0\n",
      "n_verbos                                             0\n",
      "n_verbos_subjuntivo_imperativo                       0\n",
      "n_substantivos                                       0\n",
      "n_adjetivos                                          0\n",
      "n_adverbios                                          0\n",
      "n_verbos_modais                                      0\n",
      "n_pronomes_pessoas_singulares_primeiro_segundo       0\n",
      "n_pronomes_plurais_primeiro                          0\n",
      "n_pronomes                                           0\n",
      "pausas                                               0\n",
      "n_caracteres                                         0\n",
      "compr_medio_frase                                    0\n",
      "compr_medio_palavra                                  0\n",
      "porcent_noticias_erros_ortograficos                  0\n",
      "emotividade                                          0\n",
      "diversidade                                          0\n",
      "classificacao                                        0\n",
      "dtype: int64\n",
      "Mostra o tipo de dados\n",
      "conteudo                                           object\n",
      "autor                                              object\n",
      "link                                               object\n",
      "categoria                                          object\n",
      "data_publicacao                                    object\n",
      "n_tokens                                            int64\n",
      "n_palavras_sem_pontuacao                            int64\n",
      "n_tipos                                             int64\n",
      "n_links_na_noticia                                float64\n",
      "n_palavras_maiusculas                               int64\n",
      "n_verbos                                            int64\n",
      "n_verbos_subjuntivo_imperativo                      int64\n",
      "n_substantivos                                      int64\n",
      "n_adjetivos                                         int64\n",
      "n_adverbios                                         int64\n",
      "n_verbos_modais                                     int64\n",
      "n_pronomes_pessoas_singulares_primeiro_segundo      int64\n",
      "n_pronomes_plurais_primeiro                         int64\n",
      "n_pronomes                                          int64\n",
      "pausas                                            float64\n",
      "n_caracteres                                        int64\n",
      "compr_medio_frase                                 float64\n",
      "compr_medio_palavra                               float64\n",
      "porcent_noticias_erros_ortograficos               float64\n",
      "emotividade                                       float64\n",
      "diversidade                                       float64\n",
      "classificacao                                       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"An√°lise explorat√≥ria dos dados iniciada...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "#Infos gerais do dataset\n",
    "print(f\"Dimens√µes: {df.shape[0]} linhas x {df.shape[1]}\")\n",
    "print(f\"Mem√≥ria: {df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "#Verificando valores ausentes\n",
    "print(f\"Valores ausentes por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "if 'label' in df.columns:\n",
    "    print(f\"Distribui√ß√£o de labels:\")\n",
    "    print(df['label'].value_counts())\n",
    "    print(f\"\\n Propor√ß√£o\")\n",
    "    print(df['label'].value_counts(normalize=True).round(3))\n",
    "\n",
    "print(f\"Mostra o tipo de dados\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1787e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An√°lise da Vari√°vel Target:\n",
      "==================================================\n",
      "Distribui√ß√£o das classes:\n",
      "classificacao\n",
      "1    3600\n",
      "0    3600\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Propor√ß√£o das classes:\n",
      "classificacao\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: count, dtype: float64\n",
      "üîé Dataset Fake.Br detectado ‚Äî invertendo para o padr√£o (1=real, 0=fake).\n",
      "\n",
      "Distribui√ß√£o com labels de texto:\n",
      "label_texto\n",
      "fake    3600\n",
      "real    3600\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classe 1: 3600 amostras (50.0%) - Balanceado\n",
      "\n",
      "Classe 0: 3600 amostras (50.0%) - Balanceado\n"
     ]
    }
   ],
   "source": [
    "# An√°lise detalhada da coluna target (classificacao)\n",
    "print(\"An√°lise da Vari√°vel Target:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Contagem e propor√ß√£o\n",
    "print(f\"Distribui√ß√£o das classes:\")\n",
    "if 'classificacao' in df.columns:\n",
    "    classificacao_counts = df['classificacao'].value_counts()\n",
    "elif 'Classe' in df.columns:\n",
    "    classificacao_counts = df['Classe'].value_counts()\n",
    "else:\n",
    "    raise KeyError(\"Nenhuma coluna de classifica√ß√£o encontrada (esperado 'classificacao' ou 'Classe').\")\n",
    "\n",
    "print(classificacao_counts)\n",
    "\n",
    "print(f\"\\nPropor√ß√£o das classes:\")\n",
    "classificacao_prop = classificacao_counts / classificacao_counts.sum()\n",
    "print(classificacao_prop.round(3))\n",
    "\n",
    "# Mapeamento autom√°tico conforme o dataset\n",
    "if 'classificacao' in df.columns:\n",
    "    print(\"Dataset Fake.Br detectado ‚Äî invertendo para o padr√£o (1=real, 0=fake).\")\n",
    "    df['REAL'] = df['classificacao'].map({1: 0, 0: 1})\n",
    "    df['label_texto'] = df['REAL'].map({1: 'real', 0: 'fake'})\n",
    "else:\n",
    "    raise KeyError(\"Coluna de classifica√ß√£o n√£o encontrada.\")\n",
    "\n",
    "# Exibir distribui√ß√£o com os labels textuais\n",
    "print(f\"\\nDistribui√ß√£o com labels de texto:\")\n",
    "print(df['label_texto'].value_counts())\n",
    "\n",
    "# Verificar balanceamento\n",
    "total = len(df)\n",
    "for classe, count in classificacao_counts.items():\n",
    "    pct = (count/total) * 100\n",
    "    status = \"Balanceado\" if 40 <= pct <= 60 else \"Desbalanceado\"\n",
    "    print(f\"\\nClasse {classe}: {count} amostras ({pct:.1f}%) - {status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a78a3",
   "metadata": {},
   "source": [
    "Essa an√°lise da vari√°vel classificacao mostrou que o dataset possui uma distribui√ß√£o equilibrada entre as classes ‚Äúfake‚Äù e ‚Äúreal‚Äù, o que √© ideal para o treinamento do modelo. A cria√ß√£o da coluna label_texto facilita a leitura e visualiza√ß√£o dos resultados nos gr√°ficos seguintes. Caso houvesse desbalanceamento, seria necess√°rio aplicar t√©cnicas de balanceamento como oversampling ou undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8575bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checando correspond√™ncia:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classificacao</th>\n",
       "      <th>REAL</th>\n",
       "      <th>label_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classificacao  REAL label_texto\n",
       "0              1     0        fake\n",
       "1              1     0        fake\n",
       "2              1     0        fake\n",
       "3              1     0        fake\n",
       "4              1     0        fake"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nChecando correspond√™ncia:\")\n",
    "display(df[['classificacao', 'REAL', 'label_texto']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09891147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An√°lise de Features Lingu√≠sticas\n",
      "==================================================\n",
      "Features dispon√≠veis: 21\n",
      "Lista: ['n_tokens', 'n_palavras_sem_pontuacao', 'n_tipos', 'n_links_na_noticia', 'n_palavras_maiusculas', 'n_verbos', 'n_verbos_subjuntivo_imperativo', 'n_substantivos', 'n_adjetivos', 'n_adverbios']...\n",
      "\n",
      "Top 10 features mais correlacionadas com fake/real:\n",
      "  diversidade                   : -0.810\n",
      "  n_tipos                       : +0.721\n",
      "  n_substantivos                : +0.694\n",
      "  n_caracteres                  : +0.683\n",
      "  n_palavras_sem_pontuacao      : +0.682\n",
      "  n_tokens                      : +0.680\n",
      "  n_verbos                      : +0.644\n",
      "  n_verbos_modais               : +0.613\n",
      "  n_adjetivos                   : +0.602\n",
      "  n_adverbios                   : +0.564\n"
     ]
    }
   ],
   "source": [
    "# Analisar features lingu√≠sticas\n",
    "print(\"An√°lise de Features Lingu√≠sticas\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Features num√©ricas (excluindo texto e IDs)\n",
    "features_numericas = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "features_numericas = [f for f in features_numericas if f not in ['classificacao', 'REAL']]\n",
    "\n",
    "print(f\"Features dispon√≠veis: {len(features_numericas)}\")\n",
    "print(f\"Lista: {features_numericas[:10]}...\")  # Primeiras 10\n",
    "\n",
    "# Correla√ß√£o com o target\n",
    "correlacoes = {}\n",
    "for feature in features_numericas:\n",
    "    corr = df[feature].corr(df['REAL'])\n",
    "    correlacoes[feature] = corr\n",
    "\n",
    "# Top 10 features mais correlacionadas\n",
    "top_features = sorted(correlacoes.items(), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "print(f\"\\nTop 10 features mais correlacionadas com fake/real:\")\n",
    "for feature, corr in top_features:\n",
    "    print(f\"  {feature:30}: {corr:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98960c8d",
   "metadata": {},
   "source": [
    "## 5.Prepara√ß√£o para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "078b6e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados preparados:\n",
      "Treino: 5760 amostras\n",
      "Teste: 1440 amostras\n",
      "Features: 21 vari√°veis\n"
     ]
    }
   ],
   "source": [
    "# Preparar dados para ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecionar features e target\n",
    "X = df[features_numericas]\n",
    "y = df['REAL']\n",
    "\n",
    "# Split treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Dados preparados:\")\n",
    "print(f\"Treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"Teste: {X_test.shape[0]} amostras\")\n",
    "print(f\"Features: {X_train.shape[1]} vari√°veis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad55153",
   "metadata": {},
   "source": [
    "## 6. Salvamento dos Dados Processados\n",
    "\n",
    "Salvar os dados pr√©-processados para uso nos notebooks seguintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e44b36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando dados processados...\n",
      "Arquivos existentes em ../data/processed: ['.gitkeep', 'fakeBr_dataset.csv']\n",
      "\n",
      "Estrat√©gia de salvamento:\n",
      "   - fakeBr_dataset.csv (original) ‚Üí mantido\n",
      "   - fakebr_with_labels.csv (+ colunas REAL, label_texto) ‚Üí novo\n",
      "   - X_train/test, y_train/test ‚Üí para ML\n",
      "Dataset com labels criados salvo em: ../data/processed/fakebr_with_labels.csv\n",
      "Dados de treino/teste salvos:\n",
      "   - X_train_fakebr.csv (features num√©ricas)\n",
      "   - X_test_fakebr.csv\n",
      "   - y_train_fakebr.csv (target REAL)\n",
      "   - y_test_fakebr.csv\n",
      "\n",
      "Resumo das modifica√ß√µes:\n",
      "   - Coluna 'classificacao' original: {1: 3600, 0: 3600}\n",
      "   - Nova coluna 'REAL' (invertida): {0: 3600, 1: 3600}\n",
      "   - Nova coluna 'label_texto': {'fake': 3600, 'real': 3600}\n",
      "\n",
      "Resumo final:\n",
      "Dataset FakeBR pr√©-processado com sucesso!\n",
      "7200 amostras, 21 features num√©ricas\n",
      "Classes balanceadas: 50/50 fake/real\n",
      "Arquivos salvos:\n",
      "  fakebr_with_labels.csv ‚Üí para an√°lise de fairness\n",
      "   X/y_train/test ‚Üí para treinamento de modelos\n",
      "\n",
      "Pr√≥ximo passo: Execute o notebook 03_fairness_analysis.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Salvar dados processados\n",
    "print(\"Salvando dados processados...\")\n",
    "\n",
    "# Verificar arquivos existentes\n",
    "existing_files = os.listdir(\"../data/processed\")\n",
    "print(f\"Arquivos existentes em ../data/processed: {existing_files}\")\n",
    "\n",
    "# Estrat√©gia: manter o original e criar vers√µes processadas\n",
    "print(\"\\nEstrat√©gia de salvamento:\")\n",
    "print(\"   - fakeBr_dataset.csv (original) ‚Üí mantido\")\n",
    "print(\"   - fakebr_with_labels.csv (+ colunas REAL, label_texto) ‚Üí novo\")\n",
    "print(\"   - X_train/test, y_train/test ‚Üí para ML\")\n",
    "\n",
    "# Salvar dataset com as novas colunas (REAL, label_texto)\n",
    "df.to_csv(\"../data/processed/fakebr_with_labels.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Dataset com labels criados salvo em: ../data/processed/fakebr_with_labels.csv\")\n",
    "\n",
    "# Salvar dados de treino e teste separadamente (s√≥ features num√©ricas)\n",
    "X_train.to_csv(\"../data/processed/X_train_fakebr.csv\", index=False)\n",
    "X_test.to_csv(\"../data/processed/X_test_fakebr.csv\", index=False)\n",
    "y_train.to_csv(\"../data/processed/y_train_fakebr.csv\", index=False)\n",
    "y_test.to_csv(\"../data/processed/y_test_fakebr.csv\", index=False)\n",
    "\n",
    "print(\"Dados de treino/teste salvos:\")\n",
    "print(\"   - X_train_fakebr.csv (features num√©ricas)\")\n",
    "print(\"   - X_test_fakebr.csv\") \n",
    "print(\"   - y_train_fakebr.csv (target REAL)\")\n",
    "print(\"   - y_test_fakebr.csv\")\n",
    "\n",
    "# Mostrar diferen√ßas importantes\n",
    "print(f\"\\nResumo das modifica√ß√µes:\")\n",
    "print(f\"   - Coluna 'classificacao' original: {df['classificacao'].value_counts().to_dict()}\")\n",
    "print(f\"   - Nova coluna 'REAL' (invertida): {df['REAL'].value_counts().to_dict()}\")\n",
    "print(f\"   - Nova coluna 'label_texto': {df['label_texto'].value_counts().to_dict()}\")\n",
    "\n",
    "print(f\"\\nResumo final:\")\n",
    "print(f\"Dataset FakeBR pr√©-processado com sucesso!\")\n",
    "print(f\"{df.shape[0]} amostras, {len(features_numericas)} features num√©ricas\")\n",
    "print(f\"Classes balanceadas: 50/50 fake/real\")\n",
    "print(f\"Arquivos salvos:\")\n",
    "print(f\"  fakebr_with_labels.csv ‚Üí para an√°lise de fairness\")\n",
    "print(f\"   X/y_train/test ‚Üí para treinamento de modelos\")\n",
    "print(f\"\\nPr√≥ximo passo: Execute o notebook 03_fairness_analysis.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
